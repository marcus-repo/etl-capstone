{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "published-shopping",
   "metadata": {},
   "source": [
    "# ETL Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-rating",
   "metadata": {},
   "source": [
    "- Base template for the etl.py\n",
    "- Documents cleaning steps\n",
    "- Each cleaning step is tested on the i94 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wireless-pathology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\spark\n",
      "c:\\spark\n",
      "C:\\Program Files\\Zulu\\zulu-8-jre\\\n",
      "c:\\Hadoop\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import configparser\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "print(findspark.find())\n",
    "print(os.environ['SPARK_HOME'])\n",
    "print(os.environ['JAVA_HOME'])\n",
    "print(os.environ['HADOOP_HOME'])\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import col, asc, desc, min, max, coalesce, lit\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-requirement",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "qualified-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_spark_session(local=True):\n",
    "#    \"\"\"\n",
    "#    Creates and returns spark session.\n",
    "#    \"\"\"\n",
    "#    spark = SparkSession \\\n",
    "#        .builder \\\n",
    "#        .config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:3.0.0-s_2.12,org.apache.hadoop:hadoop-aws:2.7.6\") \\\n",
    "#        .config(\"fs.s3a.access.key\", KEY) \\\n",
    "#        .config(\"fs.s3a.secret.key\", SECRET) \\\n",
    "#        .config(\"fs.s3a.endpoint\", f\"s3-{REGION}.amazonaws.com\") \\\n",
    "#        .enableHiveSupport() \\\n",
    "#        .getOrCreate()\n",
    "#    \n",
    "#    #spark.conf.set(\"mapreduce.fileoutputcommitter.algorithm.version\", \"2\")\n",
    "#    return spark\n",
    "#\n",
    "## create spark session\n",
    "#spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ranging-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session(local=True):\n",
    "    \"\"\"\n",
    "    Creates and returns spark session.\n",
    "    \"\"\"\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:3.0.0-s_2.12\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    #spark.conf.set(\"mapreduce.fileoutputcommitter.algorithm.version\", \"2\")\n",
    "    return spark\n",
    "\n",
    "# create spark session\n",
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-blanket",
   "metadata": {},
   "source": [
    "## Read I94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "selected-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schema\n",
    "# https://knowledge.udacity.com/questions/316417 - I94cit and I94 res clarification\n",
    "\n",
    "i94_schema = StructType([\n",
    "    StructField(\"cicid\", IntegerType(), True),    # id\n",
    "    StructField(\"i94yr\", IntegerType(), True),    # Year\n",
    "    StructField(\"i94mon\", IntegerType(), True),   # Month\n",
    "    StructField(\"i94cit\", IntegerType(), True),   # Country Codes I94CIT represents the country of citizenship.\n",
    "    StructField(\"i94res\", IntegerType(), True),   # Country Codes I94RES represents the country of residence.\n",
    "    StructField(\"i94port\", StringType(), True),   # e. g. 'DTH'\t=\t'DUTCH HARBOR, AK  \n",
    "    StructField(\"arrdate\", IntegerType(), True),  # ARRDATE is the Arrival Date in the USA. SAS date numeric field\n",
    "    StructField(\"i94mode\", IntegerType(), True),  # Air, Sea, Land ...\n",
    "    StructField(\"i94addr\", StringType(), True),   # States: FL, ...\n",
    "    StructField(\"depdate\", IntegerType(), True),  # SAS date numeric field \n",
    "    StructField(\"i94bir\", IntegerType(), True),   # Age of Respondent in Years\n",
    "    StructField(\"i94visa\", IntegerType(), True),  # Business, Pleasure, Student\n",
    "    StructField(\"count\", IntegerType(), True),    # COUNT - Used for summary statistics\n",
    "    StructField(\"dtadfile\", StringType(), True),  # DTADFILE - Character Date Field - Date added to I-94 Files - CIC does not use\n",
    "    StructField(\"visapost\", StringType(), True),  # VISAPOST - Department of State where where Visa was issued - CIC does not use\n",
    "    StructField(\"occup\", StringType(), True),     # OCCUP - Occupation that will be performed in U.S. - CIC does not use\n",
    "    StructField(\"entdepa\", StringType(), True),   # ENTDEPA - Arrival Flag - admitted or paroled into the U.S. - CIC does not use\n",
    "    StructField(\"entdepd\", StringType(), True),   # ENTDEPD - Departure Flag - Departed, lost I-94 or is deceased - CIC does not use\n",
    "    StructField(\"entdepu\", StringType(), True),   # ENTDEPU - Update Flag - Either apprehended, overstayed, adjusted to perm residence - CIC does not use\n",
    "    StructField(\"matflag\", StringType(), True),   # MATFLAG - Match flag - Match of arrival and departure records\n",
    "    StructField(\"biryear\", IntegerType(), True),  # BIRYEAR - 4 digit year of birth\n",
    "    StructField(\"dtaddto\", StringType(), True),   # DTADDTO - Character Date Field - Date to which admitted to U.S. (allowed to stay until) - CIC does not use\n",
    "    StructField(\"gender\", StringType(), True),    # GENDER - Non-immigrant sex\n",
    "    StructField(\"insnum\", StringType(), True),    # INSNUM - INS number\n",
    "    StructField(\"airline\", StringType(), True),   # AIRLINE - Airline used to arrive in U.S.\n",
    "    StructField(\"admnum\", DoubleType(), True),    # ADMNUM - Admission Number\n",
    "    StructField(\"fltno\", StringType(), True),     # FLTNO - Flight number of Airline used to arrive in U.S.\n",
    "    StructField(\"visatype\", StringType(), True),  # VISATYPE - Class of admission legally admitting the non-immigrant to temporarily stay in U.S.\n",
    "])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "computational-intranet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3096313\n"
     ]
    }
   ],
   "source": [
    "# read spark with schema definition\n",
    "input_data = '../../staging/i94/i94_apr16_sub.sas7bdat'\n",
    "\n",
    "df_spark = spark.read.format('com.github.saurfang.sas.spark').load(input_data, schema=i94_schema)\n",
    "\n",
    "print(df_spark.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acoustic-authentication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    6| 2016|     4|   692|   692|    XXX|  20573|   null|   null|   null|    37|      2|    1|    null|    null| null|      T|   null|      U|   null|   1979|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|    7| 2016|     4|   254|   276|    ATL|  20551|      1|     AL|   null|    25|      3|    1|20130811|     SEO| null|      G|   null|      Y|   null|   1991|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "|   15| 2016|     4|   101|   101|    WAS|  20545|      1|     MI|  20691|    55|      2|    1|20160401|    null| null|      T|      O|   null|      M|   1961|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "|   16| 2016|     4|   101|   101|    NYC|  20545|      1|     MA|  20567|    28|      2|    1|20160401|    null| null|      O|      O|   null|      M|   1988|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "|   17| 2016|     4|   101|   101|    NYC|  20545|      1|     MA|  20567|     4|      2|    1|20160401|    null| null|      O|      O|   null|      M|   2012|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-alarm",
   "metadata": {},
   "source": [
    "## Datetime conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "thorough-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://knowledge.udacity.com/questions/66798\n",
    "\n",
    "# convert SAS date to date\n",
    "def convert_sas_date(x):\n",
    "    try:\n",
    "        start = datetime(1960, 1, 1)\n",
    "        return start + timedelta(days=int(x))\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "# register udf\n",
    "udf_date_from_sas = udf(lambda x: convert_sas_date(x), DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sustained-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string format to date\n",
    "\n",
    "def convert_str_to_date(x):\n",
    "    try:\n",
    "        return datetime.strptime(x, \"%Y%m%d\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# register udf\n",
    "udf_date_from_str = udf(lambda x: convert_str_to_date(x), DateType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "julian-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add date columns\n",
    "df_spark = df_spark\\\n",
    "    .withColumn(\"arrival_date\", udf_date_from_sas(\"arrdate\")) \\\n",
    "    .withColumn(\"departure_date\", udf_date_from_sas(\"depdate\")) \\\n",
    "    .withColumn(\"dtadfile_date\", udf_date_from_str(\"dtadfile\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "digital-catalog",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+------------+--------------+-------------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|arrival_date|departure_date|dtadfile_date|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+------------+--------------+-------------+\n",
      "|    6| 2016|     4|   692|   692|    XXX|  20573|   null|   null|   null|    37|      2|    1|    null|    null| null|      T|   null|      U|   null|   1979|10282016|  null|  null|   null| 1.897628485E9| null|      B2|  2016-04-29|          null|         null|\n",
      "|    7| 2016|     4|   254|   276|    ATL|  20551|      1|     AL|   null|    25|      3|    1|20130811|     SEO| null|      G|   null|      Y|   null|   1991|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|  2016-04-07|          null|   2013-08-11|\n",
      "|   15| 2016|     4|   101|   101|    WAS|  20545|      1|     MI|  20691|    55|      2|    1|20160401|    null| null|      T|      O|   null|      M|   1961|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|  2016-04-01|    2016-08-25|   2016-04-01|\n",
      "|   16| 2016|     4|   101|   101|    NYC|  20545|      1|     MA|  20567|    28|      2|    1|20160401|    null| null|      O|      O|   null|      M|   1988|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|  2016-04-01|    2016-04-23|   2016-04-01|\n",
      "|   17| 2016|     4|   101|   101|    NYC|  20545|      1|     MA|  20567|     4|      2|    1|20160401|    null| null|      O|      O|   null|      M|   2012|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|  2016-04-01|    2016-04-23|   2016-04-01|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+------------+--------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-timeline",
   "metadata": {},
   "source": [
    "## i94cit/res number to iso-code mapping\n",
    "- Read country mapping\n",
    "- Create mapping function\n",
    "- Perform mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "floating-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read country mapping table\n",
    "\n",
    "country_map_schema = StructType([\n",
    "    StructField(\"i94_code\", IntegerType(), False),\n",
    "    StructField(\"i94_desc\", StringType(), False),\n",
    "    StructField(\"iso_code\", StringType(), False),\n",
    "])   \n",
    "\n",
    "df_con = spark.read.csv(\"../staging/countries_mapping.csv\", sep=\";\", header=True, schema=country_map_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "celtic-pharmacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------+\n",
      "|i94_code|   i94_desc|iso_code|\n",
      "+--------+-----------+--------+\n",
      "|     236|AFGHANISTAN|      AF|\n",
      "|     101|    ALBANIA|      AL|\n",
      "|     316|    ALGERIA|      DZ|\n",
      "|     102|    ANDORRA|      AD|\n",
      "|     324|     ANGOLA|      AO|\n",
      "+--------+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_con.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "macro-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join iso_code column as i94cit_id\n",
    "# if no value found set to dummy value 99 = unknown\n",
    "\n",
    "joinExpr = [df_spark.i94cit == df_con.i94_code]\n",
    "df_spark_con =\\\n",
    "    df_spark.join(df_con.select(\"i94_code\",\"iso_code\"), joinExpr, \"left_outer\")\\\n",
    "        .withColumn(\"i94cit_id\", coalesce(\"iso_code\", lit(99))).drop(\"i94_code\",\"iso_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "extensive-exhibition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|i94cit|i94cit_id|\n",
      "+------+---------+\n",
      "|   692|       EC|\n",
      "|   254|       99|\n",
      "|   101|       AL|\n",
      "|   101|       AL|\n",
      "|   101|       AL|\n",
      "+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_con.select(\"i94cit\", \"i94cit_id\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceramic-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join iso_code column as i94res_id\n",
    "# if no value found set to dummy value 99 = unknown\n",
    "\n",
    "joinExpr = [df_spark.i94res == df_con.i94_code]\n",
    "df_spark_con =\\\n",
    "    df_spark_con.join(df_con.select(\"i94_code\",\"iso_code\"), joinExpr, \"left_outer\")\\\n",
    "        .withColumn(\"i94res_id\", coalesce(\"iso_code\", lit(99))).drop(\"i94_code\",\"iso_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "statewide-great",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|i94res|i94res_id|\n",
      "+------+---------+\n",
      "|   692|       EC|\n",
      "|   276|       KR|\n",
      "|   101|       AL|\n",
      "|   101|       AL|\n",
      "|   101|       AL|\n",
      "+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_con.select(\"i94res\", \"i94res_id\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "desperate-constitutional",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+---------+\n",
      "|i94cit|i94cit_id|i94res|i94res_id|\n",
      "+------+---------+------+---------+\n",
      "|   692|       EC|   692|       EC|\n",
      "|   254|       99|   276|       KR|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   101|       AL|\n",
      "|   101|       AL|   110|       FI|\n",
      "|   101|       AL|   117|       IT|\n",
      "|   101|       AL|   117|       IT|\n",
      "|   101|       AL|   117|       IT|\n",
      "|   101|       AL|   117|       IT|\n",
      "|   101|       AL|   112|       DE|\n",
      "|   101|       AL|   112|       DE|\n",
      "|   101|       AL|   251|       IL|\n",
      "|   102|       AD|   102|       AD|\n",
      "|   102|       AD|   102|       AD|\n",
      "|   102|       AD|   102|       AD|\n",
      "|   102|       AD|   102|       AD|\n",
      "|   103|       AT|   103|       AT|\n",
      "|   103|       AT|   103|       AT|\n",
      "|   103|       AT|   103|       AT|\n",
      "|   103|       AT|   103|       AT|\n",
      "|   103|       AT|   103|       AT|\n",
      "|   103|       AT|   103|       AT|\n",
      "|   103|       AT|   103|       AT|\n",
      "|   103|       AT|   103|       AT|\n",
      "|   103|       AT|   103|       AT|\n",
      "|   103|       AT|   103|       AT|\n",
      "|   103|       AT|   103|       AT|\n",
      "+------+---------+------+---------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_con.select(\"i94cit\",\"i94cit_id\",\"i94res\",\"i94res_id\").show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-comment",
   "metadata": {},
   "source": [
    "- transformation looks fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-martin",
   "metadata": {},
   "source": [
    "##### Alternative mapping approaches: do not work on AWS EMR (missing pandas installation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "conventional-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select relevant mapping columns and convert to list\n",
    "#i94_country_code_to_iso = df_con.select(\"i94_code\", \"iso_code\").toPandas().values.tolist()\n",
    "#\n",
    "## convert to dictionary and create broadcast variable\n",
    "#country_map = spark.sparkContext.broadcast(dict(i94_country_code_to_iso))\n",
    "#\n",
    "## mapping function\n",
    "#get_country_isocode = lambda x: country_map.value.get(x, 99)\n",
    "#\n",
    "## register udf\n",
    "#country_number_to_code = udf(get_country_isocode, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "laden-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read country mapping table\n",
    "#df_con = pd.read_csv(\"./data/countries_mapping.csv\", sep=\";\", header=0, index_col=0)\n",
    "#\n",
    "## select relevant mapping columns and convert to list\n",
    "#i94_country_code_to_iso = df_con[['i94_code','iso_code']].values.tolist()\n",
    "#\n",
    "## convert to dictionary and create broadcast variable\n",
    "#country_map = spark.sparkContext.broadcast(dict(i94_country_code_to_iso))\n",
    "#\n",
    "## mapping function\n",
    "#get_country_isocode = lambda x: country_map.value.get(x, 99)\n",
    "#\n",
    "## register udf\n",
    "#country_number_to_code = udf(get_country_isocode, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "angry-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform mapping and add columns\n",
    "\n",
    "#df_spark =df_spark\\\n",
    "#            .withColumn(\"94cit_id\", country_number_to_code(\"i94cit\"))\\\n",
    "#            .withColumn(\"94res_id\", country_number_to_code(\"i94res\"))\\\n",
    "#\n",
    "#df_spark.select(\"i94cit\",\"94cit_id\",\"i94res\",\"94res_id\").show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-looking",
   "metadata": {},
   "source": [
    "## Visatype to visa_id mapping\n",
    "- Read visa_categories dimension / mapping table\n",
    "- Create mapping function\n",
    "- Perform mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "compound-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "resident-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read visa categories\n",
    "\n",
    "visa_cat_schema = StructType([\n",
    "    StructField(\"visa_category\", StringType(), False),\n",
    "    StructField(\"visa_group\", StringType(), False),\n",
    "    StructField(\"visa_desc\", StringType(), False),\n",
    "    StructField(\"visa\", StringType(), True),\n",
    "    StructField(\"visa_id\", IntegerType(), False),\n",
    "])   \n",
    "\n",
    "df_visa = spark.read.csv(\"../staging/visa_categories.csv\", sep=\";\", header=True, schema=visa_cat_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "pressing-arthritis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+---------+-------------+-------+\n",
      "|       visa_category|          visa_group|           visa_desc|visa_code|visa_code_map|visa_id|\n",
      "+--------------------+--------------------+--------------------+---------+-------------+-------+\n",
      "|Unknown Visa Cate...|        Unknown Visa|             Unknown|     null|         null|      1|\n",
      "|Immigrant Visa Ca...|Immediate Relativ...|Spouse of a U.S. ...|      IR1|          IR1|      2|\n",
      "|Immigrant Visa Ca...|Immediate Relativ...|Spouse of a U.S. ...|      CR1|          CR1|      3|\n",
      "|Immigrant Visa Ca...|Immediate Relativ...|Spouse of a U.S. ...|    K-3 *|           K3|      4|\n",
      "|Immigrant Visa Ca...|Immediate Relativ...|FiancÃ©(e) to marr...|    K-1 *|           K1|      5|\n",
      "|Immigrant Visa Ca...|Immediate Relativ...|Intercountry Adop...|      IR3|          IR3|      6|\n",
      "|Immigrant Visa Ca...|Immediate Relativ...|Intercountry Adop...|      IH3|          IH3|      7|\n",
      "|Immigrant Visa Ca...|Immediate Relativ...|Intercountry Adop...|      IR4|          IR4|      8|\n",
      "|Immigrant Visa Ca...|Immediate Relativ...|Intercountry Adop...|      IH4|          IH4|      9|\n",
      "|Immigrant Visa Ca...|Immediate Relativ...|Certain Family Me...|      IR2|          IR2|     10|\n",
      "|Immigrant Visa Ca...|Immediate Relativ...|Certain Family Me...|      CR2|          CR2|     11|\n",
      "|Immigrant Visa Ca...|Immediate Relativ...|Certain Family Me...|      IR5|          IR5|     12|\n",
      "|Immigrant Visa Ca...|Immediate Relativ...|Certain Family Me...|       F1|           F1|     13|\n",
      "|Immigrant Visa Ca...|Immediate Relativ...|Certain Family Me...|       F3|           F3|     14|\n",
      "|Immigrant Visa Ca...|Immediate Relativ...|Certain Family Me...|       F4|           F4|     15|\n",
      "|Immigrant Visa Ca...|Immediate Relativ...|Certain Family Me...|      F2A|          F2A|     16|\n",
      "|Immigrant Visa Ca...|Immediate Relativ...|Certain Family Me...|      F2B|          F2B|     17|\n",
      "|Immigrant Visa Ca...|Employer Sponsore...|   Religious Workers|       SD|           SD|     18|\n",
      "|Immigrant Visa Ca...|Employer Sponsore...|   Religious Workers|       SR|           SR|     19|\n",
      "|Immigrant Visa Ca...|Employer Sponsore...|Iraqi and Afghan ...|       SI|           SI|     20|\n",
      "|Immigrant Visa Ca...|    Other Immigrants|Diversity Immigra...|       DV|           DV|     21|\n",
      "|Immigrant Visa Ca...|    Other Immigrants|  Returning Resident|       SB|           SB|     22|\n",
      "|Immigrant Visa Ca...|Employer Sponsore...|Priority workers ...|       E1|           E1|     23|\n",
      "|Immigrant Visa Ca...|Employer Sponsore...|Professionals Hol...|       E2|           E2|     24|\n",
      "|Immigrant Visa Ca...|Employer Sponsore...|Professionals and...|       E3|           E3|     25|\n",
      "+--------------------+--------------------+--------------------+---------+-------------+-------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_visa.show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aging-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join visatype and visa_code_map\n",
    "# if no value found set to dummy value 1 = Unknown\n",
    "\n",
    "joinExpr = [df_spark.visatype == df_visa.visa_code_map]\n",
    "df_spark_visa =\\\n",
    "    df_spark.join(df_visa.select(\"visa\",\"visa_id\").dropna(), joinExpr, \"left_outer\")\\\n",
    "        .withColumn(\"visa_id\", coalesce(\"visa_id\", lit(1))).drop(\"visa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "functioning-travel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|visatype|visa_id|\n",
      "+--------+-------+\n",
      "|      B2|     57|\n",
      "|      F1|     13|\n",
      "|      B2|     57|\n",
      "|      B2|     57|\n",
      "|      B2|     57|\n",
      "|      B1|     33|\n",
      "|      B2|     57|\n",
      "|      B2|     57|\n",
      "|      B2|     57|\n",
      "|      B1|     33|\n",
      "|      B2|     57|\n",
      "|      B2|     57|\n",
      "|      B1|     33|\n",
      "|      B1|     33|\n",
      "|      B2|     57|\n",
      "|      B2|     57|\n",
      "|      B2|     57|\n",
      "|      B2|     57|\n",
      "|      B2|     57|\n",
      "|      B2|     57|\n",
      "|      B2|     57|\n",
      "|      B2|     57|\n",
      "|      B2|     57|\n",
      "|      B2|     57|\n",
      "|      B1|     33|\n",
      "+--------+-------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_visa.select(\"visatype\",\"visa_id\").show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-handling",
   "metadata": {},
   "source": [
    "- transformation looks fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "clear-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_spark_visa.select(\"visatype\",\"visa_id\").groupBy(\"visatype\",\"visa_id\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-america",
   "metadata": {},
   "source": [
    "##### Alternative mapping approaches: do not work on AWS EMR (missing pandas installation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "german-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select relevant mapping columns and convert to list\n",
    "#i94_visa_code_to_id = df_visa.select(\"visa_code_map\", \"visa_id\").toPandas().values.tolist()\n",
    "#\n",
    "## convert to dictionary and create broadcast variable\n",
    "#visa_map = spark.sparkContext.broadcast(dict(i94_visa_code_to_id))\n",
    "#\n",
    "## mapping function\n",
    "#get_visa_id = lambda x: int(visa_map.value.get(x, 1))\n",
    "#\n",
    "### register udf\n",
    "#visa_code_to_id = udf(get_visa_id, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aggressive-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i94_visa_code_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "working-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read visa categories\n",
    "#\n",
    "#df_visa = pd.read_csv(\"./data/visa_categories.csv\", sep=\";\", header=0)\n",
    "#\n",
    "## select relevant mapping columns and convert to list\n",
    "#i94_visa_code_to_id = df_visa[['visa_code_map','visa_id']].values.tolist()\n",
    "#\n",
    "## convert to dictionary and create broadcast variable\n",
    "#visa_map = spark.sparkContext.broadcast(dict(i94_visa_code_to_id))\n",
    "#\n",
    "## mapping function\n",
    "#get_visa_id = lambda x: visa_map.value.get(x, 1)\n",
    "#\n",
    "## register udf\n",
    "#visa_code_to_id = udf(get_visa_id, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eleven-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_spark = df_spark.withColumn(\"visa_id\", visa_code_to_id(\"visatype\"))\n",
    "#\n",
    "#df_spark.select(\"visatype\",\"visa_id\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-cookie",
   "metadata": {},
   "source": [
    "## Clean i94mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-request",
   "metadata": {},
   "source": [
    "- fill nulls with 9 = 'Not Reported'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "organizational-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#value i94model\n",
    "#\t1 = 'Air'\n",
    "#\t2 = 'Sea'\n",
    "#\t3 = 'Land'\n",
    "#\t9 = 'Not reported' ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "quick-headline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|i94mode|  count|\n",
      "+-------+-------+\n",
      "|   null|    239|\n",
      "|      1|2994505|\n",
      "|      3|  66660|\n",
      "|      9|   8560|\n",
      "|      2|  26349|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select(\"i94mode\").groupBy(\"i94mode\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aggregate-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null values --> fill with not reported as dictionary suggests\n",
    "\n",
    "df_spark = df_spark.fillna({\"i94mode\":9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "limited-weekly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|i94mode|  count|\n",
      "+-------+-------+\n",
      "|      1|2994505|\n",
      "|      3|  66660|\n",
      "|      9|   8799|\n",
      "|      2|  26349|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select(\"i94mode\").groupBy(\"i94mode\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-assurance",
   "metadata": {},
   "source": [
    "- all values are filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-lesbian",
   "metadata": {},
   "source": [
    "## Clean Age\n",
    "- negative age is replaced with null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "subject-moses",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "802"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.select(\"i94bir\").where(col(\"i94bir\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acting-solomon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            i94bir|\n",
      "+-------+------------------+\n",
      "|  count|           3095511|\n",
      "|   mean|41.767614458485205|\n",
      "| stddev|17.420260534588213|\n",
      "|    min|                -3|\n",
      "|    max|               114|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.describe(\"i94bir\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "sublime-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_negative_age(x):\n",
    "    if x == None:\n",
    "        return None\n",
    "    elif x < 0:\n",
    "        return None\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "# register udf\n",
    "clean_age = udf(lambda x: clean_negative_age(x), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "nominated-fifteen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               age|\n",
      "+-------+------------------+\n",
      "|  count|           3095510|\n",
      "|   mean|  41.7676289205979|\n",
      "| stddev|17.420244765569194|\n",
      "|    min|                 0|\n",
      "|    max|               114|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# perform cleaning\n",
    "\n",
    "df_spark = df_spark.withColumn(\"age\", clean_age(\"i94bir\"))\n",
    "df_spark.describe(\"age\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-macro",
   "metadata": {},
   "source": [
    "- Negative age was removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-mouth",
   "metadata": {},
   "source": [
    "## Write to parquet (test only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "reduced-friendly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- i94yr: integer (nullable = true)\n",
      " |-- i94mon: integer (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: integer (nullable = true)\n",
      " |-- i94mode: integer (nullable = false)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: integer (nullable = true)\n",
      " |-- i94bir: integer (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: integer (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- departure_date: date (nullable = true)\n",
      " |-- dtadfile_date: date (nullable = true)\n",
      " |-- i94cit_id: string (nullable = false)\n",
      " |-- i94res_id: string (nullable = false)\n",
      " |-- age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check schema\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "worst-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to parquet\n",
    "output_data = \"../model/\"\n",
    "df_spark.limit(250).repartition(1).write.parquet(output_data+\"i94.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-shoulder",
   "metadata": {},
   "source": [
    "- i94 data is provided as monthly dataset\n",
    "- this way each additional month can be added in a consistent way (mode in production is append)\n",
    "- queries will be most likely on most recent months so this also helps to increase performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-phase",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
