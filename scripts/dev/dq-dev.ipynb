{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "painted-ghana",
   "metadata": {},
   "source": [
    "# Data Quality Dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-antenna",
   "metadata": {},
   "source": [
    "Data Quality tests:\n",
    "- All Tables: has_rows, i.e. record count > 0 --> passed\n",
    "- All Table Primary Keys: has_nulls, i.e. zero null record count --> test passed\n",
    "- Fact Tables: All Foreign Keys: has_nulls, i.e. zero null record count --> test passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "virtual-implement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\spark\n",
      "c:\\spark\n",
      "C:\\Program Files\\Zulu\\zulu-8-jre\\\n",
      "c:\\Hadoop\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import configparser\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "print(findspark.find())\n",
    "print(os.environ['SPARK_HOME'])\n",
    "print(os.environ['JAVA_HOME'])\n",
    "print(os.environ['HADOOP_HOME'])\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import col, asc, desc, min, max, coalesce, lit, md5\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sixth-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session(local=True):\n",
    "    \"\"\"\n",
    "    Creates and returns spark session.\n",
    "    \"\"\"\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "# create spark session\n",
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gentle-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test definition has_rows\n",
    "\n",
    "def has_rows(path, df):\n",
    "    d = tuple()\n",
    "    # has rows test\n",
    "    if df is None:\n",
    "        d = (path, 'has_rows', 'failed', None, None)\n",
    "    else:\n",
    "        num_recs = df.count()\n",
    "        if num_recs == 0:\n",
    "            d = (path, 'has_rows', 'failed', None, num_recs)\n",
    "        else:\n",
    "            d = (path, 'has_rows', 'passed', None, num_recs)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "comic-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test definition has_nulls\n",
    "\n",
    "def has_nulls(path, df, fields=[]):\n",
    "    l = []\n",
    "    d = tuple()\n",
    "    for field in fields:\n",
    "        num_recs = df.select(field).where(col(field).isNull()).count()\n",
    "        if num_recs > 0:\n",
    "            d = (path, 'has_nulls', 'failed', field, num_recs)\n",
    "        else:\n",
    "            d = (path, 'has_nulls', 'passed', field, num_recs)\n",
    "        l.append(d)\n",
    "\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "american-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {\"../../model/i94.parquet\":['cit_country_id', 'res_country_id', 'mode_id'], \n",
    "              \"../../model/visa_categories.csv\":['visa_id'],\n",
    "              \"../../model/us_states.csv\": ['state_id'],\n",
    "              \"../../model/countries.csv\":['country_id'],\n",
    "              \"../../model/temperature.csv\":['country_id', 'month']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "greek-warner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../model/i94.parquet\n",
      "../../model/visa_categories.csv\n",
      "../../model/us_states.csv\n",
      "../../model/countries.csv\n",
      "../../model/temperature.csv\n"
     ]
    }
   ],
   "source": [
    "has_rows_result = []\n",
    "has_nulls_result = []\n",
    "\n",
    "for path, fields in input_data.items():\n",
    "    print(path)\n",
    "    \n",
    "    try:\n",
    "        if \"parquet\" in path:\n",
    "            df_spark = spark.read.parquet(path)\n",
    "        else:\n",
    "            df_spark = spark.read.csv(path, header=True, sep=\";\")       \n",
    "    except:\n",
    "        print(\"issue\")\n",
    "    else:\n",
    "        has_rows_result.append(has_rows(path, df_spark))\n",
    "        has_nulls_result.append(has_nulls(path, df_spark, fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "czech-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda t: [item for sublist in t for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "geological-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = has_rows_result + flatten(has_nulls_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "narrative-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "dq_schema = StructType([       \n",
    "    StructField('path', StringType(), True),\n",
    "    StructField('test', StringType(), True),\n",
    "    StructField('result', StringType(), True),\n",
    "    StructField('field', StringType(), True),\n",
    "    StructField('num_recs', StringType(), True),\n",
    "])\n",
    "df_results = spark.createDataFrame(data=results, schema=dq_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "attached-relation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+---------+------+--------------+--------+\n",
      "|path                           |test     |result|field         |num_recs|\n",
      "+-------------------------------+---------+------+--------------+--------+\n",
      "|../../model/i94.parquet        |has_rows |passed|null          |300     |\n",
      "|../../model/visa_categories.csv|has_rows |passed|null          |63      |\n",
      "|../../model/us_states.csv      |has_rows |passed|null          |55      |\n",
      "|../../model/countries.csv      |has_rows |passed|null          |216     |\n",
      "|../../model/temperature.csv    |has_rows |passed|null          |1836    |\n",
      "|../../model/i94.parquet        |has_nulls|passed|cit_country_id|0       |\n",
      "|../../model/i94.parquet        |has_nulls|passed|res_country_id|0       |\n",
      "|../../model/i94.parquet        |has_nulls|passed|mode_id       |0       |\n",
      "|../../model/visa_categories.csv|has_nulls|passed|visa_id       |0       |\n",
      "|../../model/us_states.csv      |has_nulls|passed|state_id      |0       |\n",
      "|../../model/countries.csv      |has_nulls|passed|country_id    |0       |\n",
      "|../../model/temperature.csv    |has_nulls|passed|country_id    |0       |\n",
      "|../../model/temperature.csv    |has_nulls|passed|month         |0       |\n",
      "+-------------------------------+---------+------+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_results.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "computational-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if result is one of the results is failed\n",
    "# note 'passed' must be exchanged with 'failed' in production environment\n",
    "# used 'passed' to simulate the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "professional-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_count = df_results.select(\"result\").where(col(\"result\")==\"passed\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "published-grade",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Data quality test did not pass.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-fd9c533f67ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfailed_count\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data quality test did not pass.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mException\u001b[0m: Data quality test did not pass."
     ]
    }
   ],
   "source": [
    "if failed_count > 0:\n",
    "    raise Exception(\"Data quality test did not pass.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-incentive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
